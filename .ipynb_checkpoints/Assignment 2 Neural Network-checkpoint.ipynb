{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef41f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb68bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv('mnist_data.csv')\n",
    "test_data = pd.read_csv('mnist_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5675d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (pixels) and labels\n",
    "X_train, y_train = train_data.iloc[:, 1:], train_data.iloc[:, 0]\n",
    "X_test, y_test = test_data.iloc[:, 1:], test_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de2330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to the range [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2526df",
   "metadata": {},
   "source": [
    "# Make Sure We won't need torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b877f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training and testing data from Pandas DataFrames to PyTorch tensors\n",
    "X_train = torch.Tensor(X_train.values.reshape(-1, 28, 28))\n",
    "X_test = torch.Tensor(X_test.values.reshape(-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decc9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target labels are also converted to PyTorch Long tensors\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4a108",
   "metadata": {},
   "source": [
    "### Define a custom dataset class that inherits from PyTorch's Dataset class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44e3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8484b5c",
   "metadata": {},
   "source": [
    "## Apply transformations to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5604ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation using PyTorch's Compose class.\n",
    "transform = transforms.Compose([transforms.Lambda(lambda x: x / 255.0)])\n",
    "\n",
    "\n",
    "# Create instances of the CustomDataset class created for the training and test datasets, with the specified transformations.\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "test_dataset = CustomDataset(X_test, y_test, transform=transform)\n",
    "\n",
    "# Split the training data into training and validation sets using train_test_split() from sklearn\n",
    "train_set, val_set = train_test_split(train_dataset, test_size=0.2, random_state=42, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48283e",
   "metadata": {},
   "source": [
    "#### Create data loaders using PyTorch's DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a906c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loaders allow for iterating over batches of data during training, validation, and testing\n",
    "# As Batch size decrease to a certain limit accuracy increases\n",
    "batch_size = 50\n",
    "# The shuffle parameter is set to True for the training loader, which shuffles the data to improve training performance\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# The validation and test loaders have shuffle set to False since ordering doesn't matter during validation and testing\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75e436",
   "metadata": {},
   "source": [
    "## Visualize a few samples from the training set (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defff500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes - Images: torch.Size([60000, 28, 28]), Labels: torch.Size([60000])\n",
      "Validation set shapes - Images: torch.Size([12000, 28, 28]), Labels: torch.Size([12000])\n",
      "Test set shapes - Images: torch.Size([10000, 28, 28]), Labels: torch.Size([10000])\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Class Distribution in Training Set:\n",
      "Digit 0: 5923 samples\n",
      "Digit 1: 6742 samples\n",
      "Digit 2: 5958 samples\n",
      "Digit 3: 6131 samples\n",
      "Digit 4: 5842 samples\n",
      "Digit 5: 5421 samples\n",
      "Digit 6: 5918 samples\n",
      "Digit 7: 6265 samples\n",
      "Digit 8: 5851 samples\n",
      "Digit 9: 5949 samples\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a few samples from the dataset\n",
    "def visualize_samples(data_loader, num_samples=5):\n",
    "    for images, labels in data_loader:\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            img = images[i].numpy().squeeze()\n",
    "            label = labels[i].item()\n",
    "\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f\"Label: {label}\")\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        break  # Break to only visualize one batch\n",
    "\n",
    "# Print shapes of the datasets:\n",
    "# Print shape of training data\n",
    "print(f\"Training set shapes - Images: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "\n",
    "# Access the images and labels from the tuple in val_set\n",
    "val_images, val_labels = zip(*val_set)\n",
    "val_images = torch.stack(val_images)\n",
    "val_labels = torch.stack(val_labels)\n",
    "\n",
    "# Print shape of validation_set data\n",
    "print(f\"Validation set shapes - Images: {val_images.shape}, Labels: {val_labels.shape}\")\n",
    "\n",
    "# Print shape of test_set data\n",
    "print(f\"Test set shapes - Images: {X_test.shape}, Labels: {y_test.shape}\")\n",
    "\n",
    "# Explore class distribution in the training set\n",
    "class_distribution = {i: 0 for i in range(10)}\n",
    "for label in y_train:\n",
    "    class_distribution[label.item()] += 1\n",
    "\n",
    "print()\n",
    "print(\"------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "print(\"Class Distribution in Training Set:\")\n",
    "for digit, count in class_distribution.items():\n",
    "    print(f\"Digit {digit}: {count} samples\")\n",
    "    \n",
    "print()\n",
    "print(\"------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "# Visualize a few samples from the training set\n",
    "visualize_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0705c",
   "metadata": {},
   "source": [
    "# Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84859c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2595473a170>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Model Class that inherits nn.Module (Pytorch)\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # Define Layers Of the Neural network (using pytorch's 'nn' module)\n",
    "    def __init__(self, in_features, h1, h2, out_features):\n",
    "        super(Model, self).__init__() # construct the nn model\n",
    "        self.flatten = nn.Flatten() # unroll\n",
    "        self.fc1 = nn.Linear(in_features, h1) # \n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "        \n",
    "    # Implementation of the forward path using the reLU activation function\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) # Unroll: flatten the input tensor (1D) before passing it through the fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Set the input size, hidden layer sizes, and output size \n",
    "in_features = 28 * 28 # size of input features (28*28 pixels)\n",
    "h1 = 128   # number of neurons at the 1st hidden layer\n",
    "h2 = 64    # number of neurons at the 2nd hidden layer\n",
    "out_features = 10   # size of output features (10) -> 10 digits from 0-9\n",
    "\n",
    "# Create Object of the model -> Instantiate the model\n",
    "model = Model(in_features, h1, h2, out_features)\n",
    "\n",
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf45038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer:\n",
    "\n",
    "# Set the criterion to measure the error\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Choose Stochastic Gradient Descent (SGD) as the optimizer (simple & Memory Efficient)\n",
    "# learning rate -> if error doesn't decrease after a bunch of iterations (epochs) donc lower it (req-> try 5 diff. lr)\n",
    "# weight_decay (the regularization term) adds L2 Regularization to the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0aff4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see how layers are going to be\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4561df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 2/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 3/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 4/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 5/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 6/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 7/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 8/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 9/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 10/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 11/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 12/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 13/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 14/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 15/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 16/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 17/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 18/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 19/20, Loss: 2.3012, Accuracy: 11.24%\n",
      "Epoch 20/20, Loss: 2.3012, Accuracy: 11.24%\n"
     ]
    }
   ],
   "source": [
    "# Define Training loop\n",
    "\n",
    "losses = [] #keep track of the losses to make sure the model is learning\n",
    "def train(model, train_loader, criterion, optimizer, epochs, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            \n",
    "            # take the error rate of fwd propagatin and feed is back thru the netwrok to fine tune the weight \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.detach().numpy)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100.0 * correct_train / total_train\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "# Train The model\n",
    "epochs = 20\n",
    "train(model, train_loader, criterion, optimizer, epochs=epochs)\n",
    "# Visualize:\n",
    "\n",
    "plt.plot(range(epochs),lo)\n",
    "plt.ylabel(\"Loss/Error\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8e862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
